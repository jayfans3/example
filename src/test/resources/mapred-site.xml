<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<!--if use yarn,please open this property and annotation other all property-->
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
</property>
<property>
        <name>mapreduce.map.memory.mb</name>
        <value>3072</value>
</property>
<property>
        <name>mapreduce.reduce.memory.mb</name>
	<value>3072</value>
</property>
<property>
        <name>mapreduce.tasktracker.map.tasks.maximum</name>
        <value>12</value>
</property>
<property>
        <name>mapreduce.tasktracker.reduce.tasks.maximum</name>
        <value>8</value>
</property>
<property>
        <name>mapreduce.shuffle.port</name>
        <value>7080</value>
</property>
<property>
        <name>mapreduce.task.io.sort.factor</name>
        <value>80</value>
</property>
<property>
        <name>mapreduce.reduce.shuffle.parallelcopies</name>
        <value>80</value>
</property>
<property>
        <name>mapreduce.job.reduce.slowstart.completedmaps</name>
        <value>0.90</value> 
</property>
<property>
	<name>mapred.child.java.opts</name>
	<value>-Xmx2800m</value>
</property>
<property>
        <name>mapreduce.map.java.opts</name>
        <value>-Xmx2800m</value>
</property>
<property>
        <name>mapreduce.task.io.sort.mb</name>
        <value>300</value>
</property>
<property>
        <name>mapreduce.input.fileinputformat.split.minsize</name>
        <value>268435456</value><!--256M-->
</property>
<property>
        <name>mapreduce.input.fileinputformat.split.maxsize</name>
        <value>536870912</value><!--512M-->
</property>
<property>
        <name>mapreduce.input.fileinputformat.split.minsize.per.node</name>
        <value>268435456</value><!--256M-->
</property>
<property>
        <name>mapreduce.input.fileinputformat.split.minsize.per.rack</name>
        <value>268435456</value><!--256M-->
</property>
<property>
        <name>mapreduce.map.cpu.vcores</name>
        <value>1</value>
</property>
<property>
        <name>mapreduce.reduce.cpu.vcores</name>
        <value>1</value>
</property>
<property>
	<name>mapred.compress.map.output</name>
	<value>true</value>
</property>
<property>
	 <name>mapred.output.compress</name>
        <value>true</value>
</property>
<!--
<property>
<name>mapred.job.tracker</name>
<value>logicaljt</value>
</property>

<property>
<name>mapred.jobtrackers.logicaljt</name>
<value>jt1,jt2</value>
<description>Comma-separated list of JobTracker IDs.</description>
</property>

<property>
<name>mapred.jobtracker.rpc-address.logicaljt.jt1</name>
<value>master20:8021</value>
</property>

<property>
<name>mapred.jobtracker.rpc-address.logicaljt.jt2</name>
<value>slave201:8022</value>
</property>

<property>
<name>mapred.job.tracker.http.address.logicaljt.jt1</name>
<value>master20:50126</value>
</property>

<property>
<name>mapred.job.tracker.http.address.logicaljt.jt2</name>
<value>slave201:50126</value>
</property>

<property>
<name>mapred.ha.jobtracker.rpc-address.logicaljt.jt1</name>
<value>master20:8024</value>
</property>

<property>
<name>mapred.ha.jobtracker.rpc-address.logicaljt.jt2</name>
<value>slave201:8024</value>
</property>
<property>
<name>mapred.ha.jobtracker.http-redirect-address.logicaljt.jt1</name>
<value>master20:50126</value>
</property>
<property>
<name>mapred.ha.jobtracker.http-redirect-address.logicaljt.jt2</name>
<value>slave201:50126</value>
</property>

<property>
  <name>mapred.task.tracker.http.address</name>
      <value>0.0.0.0:50116</value>
          </property>
          <property>


<name>mapred.local.dir</name>
<value>${hadoop.tmp.dir}/mapred/local,/data1/ocnosql/mapred/local</value>
</property>

<property>
<name>mapred.jobtracker.restart.recover</name>
<value>true</value>
</property>
<property>
<name>mapred.job.tracker.persist.jobstatus.active</name>
<value>true</value>
</property>
<property>
<name>mapred.job.tracker.persist.jobstatus.hours</name>
<value>1</value>
</property>
<property>
<name>mapred.job.tracker.persist.jobstatus.dir</name>
<value>${hadoop.tmp.dir}/mapred/jobsInfo</value>
</property>
<property>
<name>mapred.client.failover.proxy.provider.logicaljt</name>
<value>org.apache.hadoop.mapred.ConfiguredFailoverProxyProvider</value>
</property>

<property>
<name>mapred.client.failover.max.attempts</name>
<value>3</value>
</property>

<property>
<name>mapred.client.failover.sleep.base.millis</name>
<value>500</value>
</property>

<property>
<name>mapred.client.failover.sleep.max.millis</name>
<value>500</value>
</property>

<property>
<name>mapred.client.failover.connection.retries</name>
<value>0</value>
</property>

<property>
<name>mapred.client.failover.connection.retries.on.timeouts</name>
<value>0</value>
</property>

<property>
<name>mapred.ha.automatic-failover.enabled</name>
<value>true</value>
</property>

<property>
<name>mapred.ha.zkfc.port</name>
<value>8018</value>
</property>

<property>
<name>ha.zookeeper.quorum</name>
<value>master20:2181,slave201:2181,slave202:2181</value>
</property>

<property>
<name>mapred.ha.fencing.methods</name>
<value>shell(/bin/true)</value>
</property>


<property>
<name>mapred.system.dir</name>
<value>${hadoop.tmp.dir}/mapred/system</value>
</property>

<property>
<name>mapred.temp.dir</name>
<value>${hadoop.tmp.dir}/mapred/temp</value>
</property>

<property>
<name>mapred.tasktracker.map.tasks.maximum</name>
<value>2</value>
</property>

<property>
<name>mapred.tasktracker.reduce.tasks.maximum</name>
<value>1</value>
</property>

<property>
<name>mapred.compress.map.output</name>
<value>false</value>
</property>

<property>
<name>mapred.tasktracker.expiry.interval</name>
<value>30000</value>
</property>

<property>
<name>mapred.job.reuse.jvm.num.tasks</name>
<value>-1</value>
</property>

<property>
<name>mapred.task.timeout</name>
<value>30000</value>
</property>
<property>
<name>mapred.child.java.opts</name>
<value>-Xmx256m</value>
</property>

<property>
  <name>mapred.reduce.parallel.copies</name>
  <value>100</value>
  <description>The default number of parallel transfers run by reduce
        during the copy(shuffle) phase.
  </description>
</property>

<property>
  <name>mapred.job.tracker.handler.count</name>
  <value>20</value>
  <description>
          The number of server threads for the JobTracker. This should be roughly
              4% of the number of tasktracker nodes.
  </description>
</property>

<property>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>false</value>
  <description>If true, then multiple instances of some map tasks
                     may be executed in parallel.</description>
</property>

<property>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>false</value>
  <description>If true, then multiple instances of some reduce tasks
                     may be executed in parallel.</description>
</property>-->

</configuration>
